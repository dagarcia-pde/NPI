{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e68bc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import sys\n",
    "\n",
    "import PyUber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import sys\n",
    "\n",
    "import PyUber\n",
    "\n",
    "class Product:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        self.query_count = 1\n",
    "\n",
    "        self.define_modules()  # Call the method to define modules\n",
    "        self.litho_operation_decoder()\n",
    "        \n",
    "        self.lot_dict = {}\n",
    "        self.LotFlows = pd.DataFrame()\n",
    "        \n",
    "        self.xeus_source = kwargs.get('xeus_source', 'F32_PROD_XEUS')  # Access 'xeus_source' keyword argument\n",
    "        self.ret_xeus_source = kwargs.get('ret_xeus_source', 'D1D_PROD_XEUS_CENTRAL')  # Access 'xeus_source' keyword argument\n",
    "        \n",
    "        self.ret_overide = kwargs.get('ret_overide', 'ReticleConfig.xlsx')  # Access 'xeus_source' keyword argument\n",
    "        \n",
    "        self.debug_flag = kwargs.get('debug_flag', False)  # Access 'debug_flag' keyword argument\n",
    "        self.verbose = kwargs.get('verbose', False)  # Access 'debug_flag' keyword argument\n",
    "        self.npi = kwargs.get('npi', None)  # Access 'xeus_source' keyword argument\n",
    "        self.product = kwargs.get('product', None)  # Access 'xeus_source' keyword argument\n",
    "\n",
    "        if self.product is None:\n",
    "            raise ValueError(\"Product must be specified\")\n",
    "        elif self.npi is None:\n",
    "            raise ValueError(\"NPI must be specified\")\n",
    "        else:\n",
    "            df = self.run_query(self.sql_LeadLot_query(),self.xeus_source)\n",
    "            lot7 = ','.join([f\"'{lot7}'\" for lot7 in df['LOT7'].unique()])\n",
    "            self.master_flow = self.masterFlow(self.run_query(self.sql_lot_query(lot7,7),self.xeus_source))\n",
    "            \n",
    "            self.retDataRaw = self.run_query(self.sql_Reticle_query(self.product, self.product[:5]+self.product[-1:]), self.ret_xeus_source)      \n",
    "            self.retConfig = pd.read_excel(self.ret_overide, sheet_name='ReticleConfig')\n",
    "            self.Reticles = self.reticle_cleanup()\n",
    "            \n",
    "            \n",
    "    def litho_operation_decoder(self):\n",
    "        self.cond_list = [' ','#',\n",
    "                    'L58','L5B','L52','L46','L4H','L4','L5', #10nm conditions\n",
    "                    'L8xr','L8c','L8s','L8b','L86','L81','L8d','L8' #18A conditions\n",
    "                    ]         \n",
    "    def define_modules(self):\n",
    "        # Define module lists\n",
    "        modules_18A = [\n",
    "            \"LI-SAVli\", \"LI-SAYli\", \"LI-SBHcu\", \"LI-SBLcu\", \"LI-SNEli\", \"LI-SNYli\"\n",
    "        ]\n",
    "\n",
    "        modules_10nm = [\n",
    "            \"LI-BE-193\", \"LI-BE-SED\", \"LI-BE-WET\", \"LI-FE-193\", \"LI-PD-WET\",\n",
    "            \"LI-SSAFI-WET\", \"LI-WET\", \"LI-FE-248\"\n",
    "        ]        \n",
    "        \n",
    "        self.modules = modules_18A + modules_10nm\n",
    "        \n",
    "    def sql_LeadLot_query(self):\n",
    "        query = f'''\n",
    "            SELECT DISTINCT\n",
    "                LOT7\n",
    "            FROM\n",
    "                F_LOT\n",
    "            WHERE\n",
    "                PRODUCT LIKE '{self.product}'\n",
    "                AND LOT_TITLE LIKE 'NPI% LL%'\n",
    "        '''\n",
    "        return query\n",
    "    \n",
    "    def sql_lot_query(self, lot, lot_length=8):\n",
    "        \n",
    "        print (f\"Running master query for LOT: {lot}\")\n",
    "        \n",
    "        sql_adder = f'LOT IN ({lot})'\n",
    "        if lot_length == 7:\n",
    "            sql_adder = f'LOT7 IN ({lot})'\n",
    "            \n",
    "        # SQL query to get lot information\n",
    "        query = f'''\n",
    "            SELECT DISTINCT\n",
    "                lf.LOT\n",
    "                ,lf.OPERATION\n",
    "                ,lf.OPER_SHORT_DESC AS OPER_SHORT\n",
    "                ,o.oper_long_desc AS OPER_LONG\n",
    "                ,o.area AS AREA\n",
    "                ,o.module AS MODULE\n",
    "                ,MIN(lf.EXEC_SEQ) AS SEQ\n",
    "                ,max(lf.out_date) as OUT_DATE\n",
    "            FROM\n",
    "                F_LOT_FLOW lf\n",
    "                CROSS JOIN F_Facility f\n",
    "                INNER JOIN F_Operation O ON o.operation=lf.operation AND o.facility = f.facility AND o.latest_version = 'Y'\n",
    "            WHERE\n",
    "                {sql_adder}\n",
    "                AND LENGTH(lf.LOT) = 8\n",
    "            GROUP BY\n",
    "                lf.lot\n",
    "                ,lf.OPERATION\n",
    "                ,lf.OPER_SHORT_DESC\n",
    "                ,o.oper_long_desc\n",
    "                ,o.area\n",
    "                ,o.module\n",
    "        '''\n",
    "        return query\n",
    "    \n",
    "    def sql_Reticle_query(self,fab_prod,ret_name,imo_fab_list=\"'F32','F42','F12','F22','F52'\"):\n",
    "        query = f'''\n",
    "            SELECT \n",
    "                z0.commonname AS common_name\n",
    "                ,z0.title AS title\n",
    "                ,'{fab_prod}' AS FAB_PROD\n",
    "                ,z0.product AS RET_PROD\n",
    "                ,z0.rev AS rev\n",
    "                ,z0.layer AS layer\n",
    "                ,z0.step AS step\n",
    "                ,z0.platetype AS plate_type\n",
    "                ,z0.tapeintrend AS tapein_trend\n",
    "                ,z0.itotrend AS ito_trend\n",
    "                ,To_Char(z0.itocommit,'yyyy-mm-dd hh24:mi:ss') AS ito_commit\n",
    "                ,z0.itostatus AS ito_status\n",
    "                ,z0.retfabrev AS ret_fabrev\n",
    "                ,z0.fab AS fab\n",
    "                ,z0.barcode AS barcode\n",
    "                ,z0.imotrend AS imo_trend\n",
    "                ,To_Char(z0.imocommit,'yyyy-mm-dd hh24:mi:ss') AS imo_commit\n",
    "                ,z0.imostatus AS imo_status\n",
    "                ,To_Char(z0.shipdate,'yyyy-mm-dd hh24:mi:ss') AS shipdate\n",
    "                ,z0.fabrequireddate AS fab_requireddate\n",
    "                ,z0.imodotprocess AS imo_dotprocess\n",
    "                ,z0.imoishot AS imo_ishot\n",
    "                ,z0.technology AS technology\n",
    "                ,z0.toengcontact AS to_engcontact\n",
    "                ,z0.dbnames AS dbnames\n",
    "                ,To_Char(z0.last_updated_timestamp,'yyyy-mm-dd hh24:mi:ss') AS last_updated_timestamp\n",
    "            FROM \n",
    "                F_IMO_TRIFECTA_DASHBOARD z0\n",
    "            WHERE\n",
    "                1=1\n",
    "                --AND z0.last_updated_timestamp >= SYSDATE - 180 \n",
    "                AND z0.fab In ({imo_fab_list})     \n",
    "                AND (\n",
    "                    z0.product LIKE '{ret_name}'\n",
    "                )\n",
    "        '''\n",
    "        return query\n",
    "    \n",
    "    def run_query(self, query, xeus_source):\n",
    "\n",
    "        if self.verbose: print(f\"SQL Query {self.query_count}: {query}\")\n",
    "        \n",
    "        with PyUber.connect(datasource=xeus_source) as conn:\n",
    "            df = pd.read_sql(query, conn)\n",
    "        \n",
    "        if self.debug_flag:\n",
    "            filename = f'debug\\\\{self.product}_query_{str(self.query_count)}.csv'\n",
    "            self.query_count += 1\n",
    "            df.to_csv(filename, index=False)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_layer(self, row):\n",
    "        \n",
    "        if row['OPER_LONG'].find('START') != -1: return 'START'\n",
    "        if row['OPER_LONG'].find('PACK') != -1: return 'SHIP'\n",
    "        \n",
    "        value = row['OPER_SHORT']\n",
    "\n",
    "        for cond in self.cond_list:\n",
    "            value = value.replace(cond,'')\n",
    "        \n",
    "        value = value[:3]\n",
    "\n",
    "        if row['OPER_LONG'].find(value) == -1:\n",
    "            if value[0]=='M':\n",
    "                value = 'MT' + value[1]\n",
    "            else:\n",
    "                value = 'VA' + value[1]    \n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def masterFlow(self, df):\n",
    "        df3 = df.copy() \n",
    "        df3 = df3.sort_values(by='SEQ').reset_index(drop=True)\n",
    "        df3['PC_STARTS_flag'] = False\n",
    "        df3['OPERATION_flag'] = False\n",
    "        # df3['AREA_flag'] = False\n",
    "        df3['MODULE_flag'] = False\n",
    "        df3.loc[df3['MODULE'] == \"PC-STARTS\", 'PC_STARTS_flag'] = True\n",
    "        df3.loc[df3['OPERATION'] == 9812, 'OPERATION_flag'] = True\n",
    "        # df3.loc[df3['AREA'] == 'LITHO', 'AREA_flag'] = True\n",
    "        df3.loc[df3['MODULE'].isin(self.modules), 'MODULE_flag'] = True\n",
    "\n",
    "        df3 = df3[df3[['PC_STARTS_flag', 'OPERATION_flag', 'MODULE_flag']].any(axis=1)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        df3['ORDER'] = range(len(df3))\n",
    "        df3 = df3.drop(columns=['PC_STARTS_flag', 'OPERATION_flag', 'MODULE_flag','SEQ','MODULE','AREA'])\n",
    "        df3['LAYER'] = df3.apply(lambda row: self.get_layer(row), axis=1 )\n",
    "\n",
    "        df3 = df3[['ORDER', 'OPERATION', 'OPER_SHORT', 'OPER_LONG', 'LAYER']]\n",
    "        \n",
    "        return df3\n",
    "    \n",
    "    def load_lot_list(self, lot_list):\n",
    "        \n",
    "        for lot in lot_list:\n",
    "            print(f\"LOT: {lot['LOT']}, LOT_TYPE: {lot['LOT_TYPE']}\")\n",
    "            if lot['LOT'] not in self.lot_dict:\n",
    "                self.add_Lot(lot['LOT'], lot['LOT_TYPE'], lot['COMMIT'])\n",
    "    def add_Lot(self, lot,lot_type, commit=None):\n",
    "        df = self.run_query(self.sql_lot_query(f\"'{lot}'\"), self.xeus_source)\n",
    "        df['LOT_TYPE'] = lot_type\n",
    "        df['NPI'] = self.npi\n",
    "        df['COMMIT'] = commit\n",
    "        mf = self.master_flow\n",
    "        df2 = pd.merge(df[['NPI','LOT_TYPE','LOT','COMMIT','OPERATION','OPER_SHORT','OPER_LONG','OUT_DATE']], mf[['OPER_SHORT','ORDER','LAYER']], left_on=['OPER_SHORT'], right_on=['OPER_SHORT'], how='inner').sort_values(by='ORDER').reset_index(drop=True)\n",
    "\n",
    "        commit = df2.iloc[0]['COMMIT']\n",
    "        release_date = df2.iloc[0]['OUT_DATE']\n",
    "        reticle_layers = df2['ORDER'].max()\n",
    "\n",
    "        TPT = (commit - release_date).days\n",
    "        DPML = TPT/reticle_layers\n",
    "\n",
    "        df2['DPML_CUM'] = df2['ORDER'].apply(lambda x: DPML * (x))\n",
    "        df2['PLAN'] = release_date + pd.to_timedelta(df2['DPML_CUM'], unit='D')\n",
    "\n",
    "        df2 = df2.drop('DPML_CUM', axis=1)\n",
    "        \n",
    "        self.lot_dict[lot] = df2\n",
    "        \n",
    "        if lot not in self.LotFlows:\n",
    "            self.LotFlows = pd.concat([self.LotFlows, df2.assign(LOT=lot)], ignore_index=True)\n",
    "        \n",
    "    def cleanRetCol(self,dt):\n",
    "        try:\n",
    "            dt = pd.to_datetime(dt)\n",
    "            return dt\n",
    "        except ValueError:\n",
    "            dt = dt.str.replace('~','')\n",
    "            dt = pd.to_datetime(dt)\n",
    "            return dt\n",
    "        \n",
    "    def convert_to_days(self,col,min_val):\n",
    "        col = col - min_val\n",
    "        col = col.apply(lambda x: x.days if x>pd.Timedelta(days=0) else 0)\n",
    "        return col\n",
    "\n",
    "    def cleanupCommit(self,row):\n",
    "        cutoff_date = pd.Timestamp.now() - pd.Timedelta(days=180)\n",
    "        \n",
    "        if row['IMO_TREND'] < cutoff_date:\n",
    "            return row['IMO_COMMIT']\n",
    "        else:\n",
    "            return row['IMO_TREND']    \n",
    "        \n",
    "    def reticle_version_handling(self,df, ret_version):\n",
    "        \"\"\"\n",
    "        Uses the reticle data version input to overide and select specific reticles to use in tracking\n",
    "        \"\"\"\n",
    "        # df['VER'] = df['RET_PROD'].str[:3]\n",
    "        df['VER'] = df['TITLE'].str[:3]\n",
    "        merged_data = df.merge(ret_version, how='left', on=['RET_PROD', 'LAYER'])\n",
    "        df = merged_data[(merged_data['VER'] == merged_data['VERSION']) | merged_data['VERSION'].isna()]\n",
    "        df.drop(columns=['VER','VERSION'], inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def reticle_cleanup(self):\n",
    "        RetData = self.retDataRaw.copy()\n",
    "        col_list =['TAPEIN_TREND','ITO_TREND','ITO_COMMIT','IMO_TREND','IMO_COMMIT','SHIPDATE','FAB_REQUIREDDATE']\n",
    "        for col in col_list:\n",
    "            RetData[col] = self.cleanRetCol(RetData[col])\n",
    "        if self.retConfig is not None:\n",
    "            RetData = self.reticle_version_handling(RetData, self.retConfig)\n",
    "        RetData['IMO_TREND'] = RetData.apply(lambda row: self.cleanupCommit(row), axis =1)\n",
    "        indexNames = RetData[RetData['IMO_STATUS']=='Rejected'].index\n",
    "        RetData.drop(indexNames, inplace=True)\n",
    "\n",
    "        indexNames = RetData[RetData['IMO_STATUS']=='Processing - Hold With Waiver'].index\n",
    "        RetData.drop(indexNames, inplace=True)\n",
    "\n",
    "        RetData['RetRev'] = RetData['TITLE'].str.slice(0, 3) \n",
    "        RetData['RetNum'] = RetData['TITLE'].str[3:4]   \n",
    "        shipped_data = RetData[RetData['IMO_STATUS'] == 'Shipped'][['FAB_PROD', 'LAYER']].drop_duplicates()\n",
    "        RetData = RetData[~((RetData['IMO_STATUS'] != 'Shipped') & (RetData['LAYER'].isin(shipped_data['LAYER'])) & (RetData['RET_PROD'].isin(shipped_data['FAB_PROD'])))]\n",
    "\n",
    "        RetData = RetData.sort_values(by='IMO_COMMIT').drop_duplicates(subset=['LAYER'], keep='first')\n",
    "        RetData = pd.pivot_table(RetData,index=['LAYER'], values=['TAPEIN_TREND','ITO_TREND','FAB_REQUIREDDATE','IMO_TREND','SHIPDATE'], aggfunc=np.min).reset_index()        \n",
    "        \n",
    "        return RetData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0558709",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1 = Product(product='8PXMCV%G',\n",
    "                xeus_source = 'F32_PROD_XEUS',\n",
    "                debug_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb01cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
